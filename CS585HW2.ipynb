{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T05:14:54.253275500Z",
     "start_time": "2024-02-12T05:14:54.246860700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WEBCAM = True\n",
    "VIDEO_NAME = \"fingers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T05:15:05.792998700Z",
     "start_time": "2024-02-12T05:14:54.748098100Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Recognition\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "if WEBCAM:\n",
    "    # Access the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "else:\n",
    "    cap = cv2.VideoCapture(f'videos/{VIDEO_NAME}.mp4')\n",
    "\n",
    "def detect_five_fingers(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    \n",
    "    # Thresholding to get the hand segment\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Assume the largest contour is the hand\n",
    "        hand_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Approximate the contour to a polygon\n",
    "        approx = cv2.approxPolyDP(hand_contour, 0.02*cv2.arcLength(hand_contour, True), True)\n",
    "        \n",
    "        # Convex Hull\n",
    "        hull = cv2.convexHull(hand_contour, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(hand_contour, hull)\n",
    "        \n",
    "        # Finger counting\n",
    "        if defects is not None:\n",
    "            fingers = 0\n",
    "            for i in range(defects.shape[0]):\n",
    "                s, e, f, d = defects[i, 0]\n",
    "                start = tuple(hand_contour[s][0])\n",
    "                end = tuple(hand_contour[e][0])\n",
    "                far = tuple(hand_contour[f][0])\n",
    "                \n",
    "                # Apply angle rule to count fingers\n",
    "                a = ((end[0] - start[0])**2 + (end[1] - start[1])**2)**0.5\n",
    "                b = ((far[0] - start[0])**2 + (far[1] - start[1])**2)**0.5\n",
    "                c = ((end[0] - far[0])**2 + (end[1] - far[1])**2)**0.5\n",
    "                angle = (a**2 + b**2 - c**2) / (2*a*b)\n",
    "                \n",
    "                # If angle between fingers is less than 90 degrees, it's considered as a finger\n",
    "                if angle <= 0.5:\n",
    "                    fingers += 1\n",
    "            \n",
    "            # if fingers == 4:  # We count the valleys (4) for 5 fingers\n",
    "            #     return \"Five fingers\"\n",
    "            return f\"{fingers + 1} fingers.\"\n",
    "            \n",
    "    return \"No contours of hand\"\n",
    "\n",
    "def show_frames():\n",
    "    # Capture the current frame\n",
    "    ret, frame = cap.read()\n",
    "      \n",
    "    # Detect the number of fingers\n",
    "    gesture = detect_five_fingers(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    # Repeat after an interval to capture continuously\n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "\n",
    "def parse_videos():\n",
    "    # Capture the current frame\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    while ret:\n",
    "        # run with the functions we tested before, and write the process frame into the video file\n",
    "        # image_process = preprocess_image(image)\n",
    "        # image_detect = draw_detected_cat(image_process)\n",
    "        # vidwrite.write(image_detect) # write frame into video\n",
    "\n",
    "        # Detect the number of fingers\n",
    "        gesture = detect_five_fingers(frame)\n",
    "    \n",
    "        # Update the gesture name variable\n",
    "        gesture_name_var.set(gesture)\n",
    "    \n",
    "        # Convert the image from BGR to RGB\n",
    "        cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(cv2image)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        video_label.imgtk = imgtk\n",
    "        video_label.configure(image=imgtk)\n",
    "    \n",
    "        # Repeat after an interval to capture continuously\n",
    "        time.sleep(0.05)\n",
    "        root.update()\n",
    "        \n",
    "        ret, frame = cap.read() # read frame from video\n",
    "    \n",
    "# Start the GUI\n",
    "if WEBCAM:\n",
    "    show_frames()\n",
    "else:\n",
    "    parse_videos()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T22:42:30.266899500Z",
     "start_time": "2024-02-11T22:42:20.504849700Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Recognition\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "if WEBCAM:\n",
    "    # Access the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "else:\n",
    "    cap = cv2.VideoCapture(f'videos/{VIDEO_NAME}.mp4')\n",
    "\n",
    "\n",
    "def filter_skin(image):\n",
    "    # Convert to YCrCb color space, which is better for skin color detection\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define lower and upper bounds for skin color\n",
    "    lower_bound = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    upper_bound = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "    \n",
    "    # Create a mask for skin color\n",
    "    mask = cv2.inRange(ycrcb, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to get the skin region\n",
    "    skin_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return skin_region\n",
    "\n",
    "\n",
    "def preprocess_for_contours(image):\n",
    "    # Filter skin color first\n",
    "    skin_region = filter_skin(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    \n",
    "    # Thresholding to get the hand segment\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "\n",
    "\n",
    "# Function to detect fist\n",
    "def detect_fist(image):\n",
    "    skin_region = filter_skin(image)\n",
    "    # Convert to grayscale\n",
    "\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    \n",
    "    # Thresholding to get the hand segment\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Assume the largest contour is the hand\n",
    "        hand_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(hand_contour)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Approximate the contour to a polygon\n",
    "        approx = cv2.approxPolyDP(hand_contour, 0.02*cv2.arcLength(hand_contour, True), True)\n",
    "        \n",
    "        # If the number of vertices is small, we might have a fist\n",
    "        if len(approx) < 5:\n",
    "            return \"Fist\",image\n",
    "    return \"Not Fist\", image\n",
    "\n",
    "\n",
    "def detect_five_fingers(image):\n",
    "\n",
    "    skin_region = filter_skin(image)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    \n",
    "    # Thresholding to get the hand segment\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Assume the largest contour is the hand\n",
    "        hand_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(hand_contour)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        \n",
    "        # Approximate the contour to a polygon\n",
    "        approx = cv2.approxPolyDP(hand_contour, 0.02*cv2.arcLength(hand_contour, True), True)\n",
    "        \n",
    "        # Convex Hull\n",
    "        hull = cv2.convexHull(hand_contour, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(hand_contour, hull)\n",
    "        \n",
    "        # Finger counting\n",
    "        if defects is not None:\n",
    "            fingers = 0\n",
    "            for i in range(defects.shape[0]):\n",
    "                s, e, f, d = defects[i, 0]\n",
    "                start = tuple(hand_contour[s][0])\n",
    "                end = tuple(hand_contour[e][0])\n",
    "                far = tuple(hand_contour[f][0])\n",
    "                \n",
    "                # Apply angle rule to count fingers\n",
    "                a = ((end[0] - start[0])**2 + (end[1] - start[1])**2)**0.5\n",
    "                b = ((far[0] - start[0])**2 + (far[1] - start[1])**2)**0.5\n",
    "                c = ((end[0] - far[0])**2 + (end[1] - far[1])**2)**0.5\n",
    "                angle = (a**2 + b**2 - c**2) / (2*a*b)\n",
    "                \n",
    "                # If angle between fingers is less than 90 degrees, it's considered as a finger\n",
    "                if angle <= 0.5:\n",
    "                    fingers += 1\n",
    "            \n",
    "            if fingers == 4:  # We count the valleys (4) for 5 fingers\n",
    "                return \"Five fingers\", image\n",
    "    return \"Not five fingers\", image\n",
    "# Modify the existing function to handle both fist and five fingers\n",
    "def detect_gestures(image):\n",
    "    fist, image_with_box = detect_fist(image)\n",
    "    if fist == \"Fist\":\n",
    "        return \"Fist\", image_with_box\n",
    "    \n",
    "    five_fingers, image_with_box = detect_five_fingers(image)\n",
    "    if five_fingers == \"Five fingers\":\n",
    "        return \"Five fingers\", image_with_box\n",
    "    \n",
    "    return \"Unknown gesture\", image\n",
    "\n",
    "# Update the show_frames function to use the new detect_gestures function\n",
    "def show_frames():\n",
    "    # Capture the current frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Detect the gesture\n",
    "    gesture, frame_with_box = detect_gestures(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    # Repeat after an interval to capture continuously\n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "# Start the GUI\n",
    "if WEBCAM:\n",
    "    show_frames()\n",
    "else:\n",
    "    parse_videos()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best one yet at detecting the hand\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Fist Detection\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def filter_skin(image):\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define lower and upper bounds for skin color\n",
    "    lower_bound = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    upper_bound = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "    \n",
    "    # Create a mask for skin color\n",
    "    mask = cv2.inRange(ycrcb, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to get the skin region\n",
    "    skin_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return skin_region\n",
    "\n",
    "# Function to detect fist\n",
    "def detect_fist(image):\n",
    "    skin_region = filter_skin(image)\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on size\n",
    "    frame_area = image.shape[0] * image.shape[1]\n",
    "    contours = [cnt for cnt in contours if 0.01 < cv2.contourArea(cnt) / frame_area < 0.1]\n",
    "\n",
    "    for contour in contours:\n",
    "        hull = cv2.convexHull(contour)\n",
    "        if cv2.isContourConvex(hull):\n",
    "            x, y, w, h = cv2.boundingRect(hull)\n",
    "            aspect_ratio = w / float(h)\n",
    "            if 0.75 < aspect_ratio < 1.25:\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                return \"Fist Detected\", image\n",
    "\n",
    "    return \"No Fist Detected\", image\n",
    "\n",
    "\n",
    "\n",
    "# Function to display frames in the GUI\n",
    "def show_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        return\n",
    "    \n",
    "    # Detect the gesture\n",
    "    gesture, frame_with_box = detect_fist(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    # Repeat after an interval to capture continuously\n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "# Start the GUI\n",
    "show_frames()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works for fist and open hand\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def filter_skin(image):\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define lower and upper bounds for skin color\n",
    "    lower_bound = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    upper_bound = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "    \n",
    "    # Create a mask for skin color\n",
    "    mask = cv2.inRange(ycrcb, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to get the skin region\n",
    "    skin_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return skin_region\n",
    "\n",
    "def detect_hand_gesture(image):\n",
    "    skin_region = filter_skin(image)\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on size\n",
    "    frame_area = image.shape[0] * image.shape[1]\n",
    "    contours = [cnt for cnt in contours if 0.01 < cv2.contourArea(cnt) / frame_area < 0.1]\n",
    "\n",
    "    for contour in contours:\n",
    "        hull = cv2.convexHull(contour, returnPoints=False)\n",
    "        if len(hull) > 3:\n",
    "            defects = cv2.convexityDefects(contour, hull)\n",
    "            if defects is not None:\n",
    "                cnt_defects = 0\n",
    "                for i in range(defects.shape[0]):  # Counting the defects\n",
    "                    s, e, f, d = defects[i][0]\n",
    "                    if d > 1000:  # Filter based on defect depth\n",
    "                        cnt_defects += 1\n",
    "                \n",
    "                hull_area = cv2.contourArea(cv2.convexHull(contour))\n",
    "                solidity = cv2.contourArea(contour) / hull_area\n",
    "                \n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "                \n",
    "                if cnt_defects <= 2 and 0.75 < aspect_ratio < 1.25 and solidity > 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    return \"Fist Detected\", image\n",
    "                elif cnt_defects > 2 and solidity < 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                    return \"Five Fingers Detected\", image\n",
    "\n",
    "    return \"No Gesture Detected\", image\n",
    "\n",
    "def show_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        return\n",
    "    \n",
    "    # Detect the gesture\n",
    "    gesture, frame_with_box = detect_hand_gesture(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "# Start the GUI\n",
    "show_frames()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index finger is L detection, best code so far\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def filter_skin(image):\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define lower and upper bounds for skin color\n",
    "    lower_bound = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    upper_bound = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "    \n",
    "    # Create a mask for skin color\n",
    "    mask = cv2.inRange(ycrcb, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to get the skin region\n",
    "    skin_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return skin_region\n",
    "\n",
    "\n",
    "def detect_hand_gesture(image):\n",
    "    skin_region = filter_skin(image)\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on size\n",
    "    frame_area = image.shape[0] * image.shape[1]\n",
    "    contours = [cnt for cnt in contours if 0.01 < cv2.contourArea(cnt) / frame_area < 0.1]\n",
    "\n",
    "    for contour in contours:\n",
    "        hull = cv2.convexHull(contour, returnPoints=False)\n",
    "        if len(hull) > 3:\n",
    "            defects = cv2.convexityDefects(contour, hull)\n",
    "            if defects is not None:\n",
    "                cnt_defects = 0\n",
    "                extended_fingers = 0\n",
    "                for i in range(defects.shape[0]):  # Counting the defects\n",
    "                    s, e, f, d = defects[i][0]\n",
    "                    start = tuple(contour[s][0])\n",
    "                    end = tuple(contour[e][0])\n",
    "                    far = tuple(contour[f][0])\n",
    "                    \n",
    "                    a = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "                    b = np.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "                    c = np.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "                    angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  # Cosine theorem\n",
    "                    \n",
    "                    if np.degrees(angle) < 90:  # Open angle\n",
    "                        cnt_defects += 1\n",
    "                        if d > 10000:  # Using defect depth to infer extended finger\n",
    "                            extended_fingers += 1\n",
    "                \n",
    "                hull_area = cv2.contourArea(cv2.convexHull(contour))\n",
    "                solidity = cv2.contourArea(contour) / hull_area\n",
    "                \n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "                \n",
    "                # Assuming \"One Index Finger Up\" if exactly one extended finger is detected\n",
    "                if extended_fingers == 1:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 165, 0), 2)  # Orange bounding box\n",
    "                    return \"One Index Finger Up Detected\", image\n",
    "                elif cnt_defects > 2 and solidity < 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Blue for open hand\n",
    "                    return \"Five Fingers Detected\", image\n",
    "                elif cnt_defects <= 2 and 0.75 < aspect_ratio < 1.25 and solidity > 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)  # Green for fist\n",
    "                    return \"Fist Detected\", image\n",
    "\n",
    "    return \"No Gesture Detected\", image\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "def show_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        return\n",
    "    \n",
    "    # Detect the gesture\n",
    "    gesture, frame_with_box = detect_hand_gesture(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "# Start the GUI\n",
    "show_frames()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index finger is L detection, This kind of works, but 5 fingers vs index finger and thumb can both be L\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def filter_skin(image):\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define lower and upper bounds for skin color\n",
    "    lower_bound = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    upper_bound = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "    \n",
    "    # Create a mask for skin color\n",
    "    mask = cv2.inRange(ycrcb, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to get the skin region\n",
    "    skin_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return skin_region\n",
    "\n",
    "\n",
    "def detect_hand_gesture(image):\n",
    "    skin_region = filter_skin(image)\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on size\n",
    "    frame_area = image.shape[0] * image.shape[1]\n",
    "    contours = [cnt for cnt in contours if 0.01 < cv2.contourArea(cnt) / frame_area < 0.1]\n",
    "\n",
    "    for contour in contours:\n",
    "        hull = cv2.convexHull(contour, returnPoints=False)\n",
    "        if len(hull) > 3:\n",
    "            defects = cv2.convexityDefects(contour, hull)\n",
    "            if defects is not None:\n",
    "                l_shape_detected = False  # Initialize L shape detection flag\n",
    "                for i in range(defects.shape[0]):\n",
    "                    s, e, f, d = defects[i][0]\n",
    "                    start = tuple(contour[s][0])\n",
    "                    end = tuple(contour[e][0])\n",
    "                    far = tuple(contour[f][0])\n",
    "                    \n",
    "                    a = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "                    b = np.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "                    c = np.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "                    angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  # Cosine theorem\n",
    "                    \n",
    "                    if np.degrees(angle) > 80 and np.degrees(angle) < 100 and d > 10000:  # Approximate angle for L shape\n",
    "                        l_shape_detected = True\n",
    "                        break  # Exit the loop if L shape is detected\n",
    "\n",
    "                if l_shape_detected:\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 165, 0), 2)  # Orange bounding box for L shape\n",
    "                    return \"L Shape Detected\", image\n",
    "\n",
    "                cnt_defects = 0\n",
    "                for i in range(defects.shape[0]):  # Counting the defects\n",
    "                    s, e, f, d = defects[i][0]\n",
    "                    start = tuple(contour[s][0])\n",
    "                    end = tuple(contour[e][0])\n",
    "                    far = tuple(contour[f][0])\n",
    "                    \n",
    "                    a = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "                    b = np.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "                    c = np.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "                    angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  # Cosine theorem\n",
    "                    \n",
    "                    if angle <= np.radians(90):  # Open angle\n",
    "                        cnt_defects += 1\n",
    "                \n",
    "                hull_area = cv2.contourArea(cv2.convexHull(contour))\n",
    "                solidity = cv2.contourArea(contour) / hull_area\n",
    "                \n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "                \n",
    "                if cnt_defects > 2 and solidity < 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Blue for open hand\n",
    "                    return \"Five Fingers Detected\", image\n",
    "                elif cnt_defects <= 2 and 0.75 < aspect_ratio < 1.25 and solidity > 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)  # Green for fist\n",
    "                    return \"Fist Detected\", image\n",
    "\n",
    "    return \"No Gesture Detected\", image\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "def show_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        return\n",
    "    \n",
    "    # Detect the gesture\n",
    "    gesture, frame_with_box = detect_hand_gesture(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "# Start the GUI\n",
    "show_frames()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best code so far, works for L, open hand and fist\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def filter_skin(image):\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define lower and upper bounds for skin color\n",
    "    lower_bound = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    upper_bound = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "    \n",
    "    # Create a mask for skin color\n",
    "    mask = cv2.inRange(ycrcb, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to get the skin region\n",
    "    skin_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return skin_region\n",
    "\n",
    "\n",
    "           \n",
    "def detect_hand_gesture(image):\n",
    "    skin_region = filter_skin(image)\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on size\n",
    "    frame_area = image.shape[0] * image.shape[1]\n",
    "    contours = [cnt for cnt in contours if 0.01 < cv2.contourArea(cnt) / frame_area < 0.1]\n",
    "\n",
    "    for contour in contours:\n",
    "        hull = cv2.convexHull(contour, returnPoints=False)\n",
    "        if len(hull) > 3:\n",
    "            defects = cv2.convexityDefects(contour, hull)\n",
    "            if defects is not None:\n",
    "                cnt_defects = 0\n",
    "                for i in range(defects.shape[0]):  # Count all defects for overall hand posture\n",
    "                    s, e, f, d = defects[i][0]\n",
    "                    start = tuple(contour[s][0])\n",
    "                    end = tuple(contour[e][0])\n",
    "                    far = tuple(contour[f][0])\n",
    "                    \n",
    "                    a = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "                    b = np.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "                    c = np.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "                    angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  # Cosine theorem\n",
    "                    \n",
    "                    if angle <= np.radians(90):  # Open angle\n",
    "                        cnt_defects += 1\n",
    "                \n",
    "                # L shape detection logic\n",
    "                l_shape_defects_count = 0\n",
    "                for i in range(defects.shape[0]):\n",
    "                    s, e, f, d = defects[i][0]\n",
    "                    start = tuple(contour[s][0])\n",
    "                    end = tuple(contour[e][0])\n",
    "                    far = tuple(contour[f][0])\n",
    "                    \n",
    "                    a = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "                    b = np.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "                    c = np.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "                    angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))\n",
    "                    \n",
    "                    # Angle criteria for L shape\n",
    "                    if np.degrees(angle) >= 80 and np.degrees(angle) <= 100:\n",
    "                        l_shape_defects_count += 1\n",
    "                \n",
    "                hull_area = cv2.contourArea(cv2.convexHull(contour))\n",
    "                solidity = cv2.contourArea(contour) / hull_area\n",
    "                \n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "                \n",
    "                # Adjusted criteria for L shape detection\n",
    "                if l_shape_defects_count == 1 and cnt_defects <= 1:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 165, 0), 2)  # Orange bounding box for L shape\n",
    "                    return \"L Shape Detected\", image\n",
    "                elif cnt_defects > 3 and solidity < 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Blue for open hand\n",
    "                    return \"Five Fingers Detected\", image\n",
    "                elif cnt_defects <= 2 and 0.75 < aspect_ratio < 1.25 and solidity > 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)  # Green for fist\n",
    "                    return \"Fist Detected\", image\n",
    "\n",
    "    return \"No Gesture Detected\", image\n",
    "\n",
    "      \n",
    "def show_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        return\n",
    "    \n",
    "    # Detect the gesture\n",
    "    gesture, frame_with_box = detect_hand_gesture(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "# Start the GUI\n",
    "show_frames()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best code so far, works for L, peace sign, open hand and fist\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Detection\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def filter_skin(image):\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define lower and upper bounds for skin color\n",
    "    lower_bound = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    upper_bound = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "    \n",
    "    # Create a mask for skin color\n",
    "    mask = cv2.inRange(ycrcb, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to get the skin region\n",
    "    skin_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return skin_region\n",
    "\n",
    "\n",
    "           \n",
    "def detect_hand_gesture(image):\n",
    "    skin_region = filter_skin(image)\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on size\n",
    "    frame_area = image.shape[0] * image.shape[1]\n",
    "    contours = [cnt for cnt in contours if 0.01 < cv2.contourArea(cnt) / frame_area < 0.1]\n",
    "\n",
    "    for contour in contours:\n",
    "        hull = cv2.convexHull(contour, returnPoints=False)\n",
    "        if len(hull) > 3:\n",
    "            defects = cv2.convexityDefects(contour, hull)\n",
    "            if defects is not None:\n",
    "                cnt_defects = 0\n",
    "                for i in range(defects.shape[0]):  # Count all defects for overall hand posture\n",
    "                    s, e, f, d = defects[i][0]\n",
    "                    start = tuple(contour[s][0])\n",
    "                    end = tuple(contour[e][0])\n",
    "                    far = tuple(contour[f][0])\n",
    "                    \n",
    "                    a = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "                    b = np.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "                    c = np.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "                    angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  # Cosine theorem\n",
    "                    \n",
    "                    if angle <= np.radians(90):  # Open angle\n",
    "                        cnt_defects += 1\n",
    "                \n",
    "                # L shape detection logic\n",
    "                l_shape_defects_count = 0\n",
    "                peace_sign = 0\n",
    "                for i in range(defects.shape[0]):\n",
    "                    s, e, f, d = defects[i][0]\n",
    "                    start = tuple(contour[s][0])\n",
    "                    end = tuple(contour[e][0])\n",
    "                    far = tuple(contour[f][0])\n",
    "                    \n",
    "                    a = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "                    b = np.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "                    c = np.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "                    angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))\n",
    "                    \n",
    "                    # Angle criteria for L shape\n",
    "                    if np.degrees(angle) >= 80 and np.degrees(angle) <= 100:\n",
    "                        l_shape_defects_count += 1\n",
    "                    elif np.degrees(angle) <= 55:\n",
    "                        peace_sign+=1\n",
    "                \n",
    "                hull_area = cv2.contourArea(cv2.convexHull(contour))\n",
    "                solidity = cv2.contourArea(contour) / hull_area\n",
    "                \n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "                \n",
    "                # Adjusted criteria for L shape detection\n",
    "                if l_shape_defects_count == 1 and cnt_defects <= 1:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)  # Red bounding box for L shape\n",
    "                    return \"L Shape Detected\", image\n",
    "                elif peace_sign == 1 and cnt_defects <=1:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 165, 0), 2)  # Cyan bounding box for L shape\n",
    "                    return \"Peace sign detected\", image\n",
    "                elif cnt_defects > 3 and solidity < 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Blue for open hand\n",
    "                    return \"Five Fingers Detected\", image\n",
    "                elif cnt_defects <= 2 and 0.75 < aspect_ratio < 1.25 and solidity > 0.75:\n",
    "                    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)  # Green for fist\n",
    "                    return \"Fist Detected\", image\n",
    "\n",
    "    return \"No Gesture Detected\", image\n",
    "\n",
    "      \n",
    "def show_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        return\n",
    "    \n",
    "    # Detect the gesture\n",
    "    gesture, frame_with_box = detect_hand_gesture(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "# Start the GUI\n",
    "show_frames()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
