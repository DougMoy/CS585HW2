{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "WEBCAM = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T22:39:54.483661500Z",
     "start_time": "2024-02-11T22:39:54.481157200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T22:40:00.617085500Z",
     "start_time": "2024-02-11T22:39:54.487661400Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Recognition\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "if WEBCAM:\n",
    "    # Access the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "else:\n",
    "    cap = cv2.VideoCapture('videos/thumbUp.mp4')\n",
    "\n",
    "def detect_five_fingers(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    \n",
    "    # Thresholding to get the hand segment\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Assume the largest contour is the hand\n",
    "        hand_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Approximate the contour to a polygon\n",
    "        approx = cv2.approxPolyDP(hand_contour, 0.02*cv2.arcLength(hand_contour, True), True)\n",
    "        \n",
    "        # Convex Hull\n",
    "        hull = cv2.convexHull(hand_contour, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(hand_contour, hull)\n",
    "        \n",
    "        # Finger counting\n",
    "        if defects is not None:\n",
    "            fingers = 0\n",
    "            for i in range(defects.shape[0]):\n",
    "                s, e, f, d = defects[i, 0]\n",
    "                start = tuple(hand_contour[s][0])\n",
    "                end = tuple(hand_contour[e][0])\n",
    "                far = tuple(hand_contour[f][0])\n",
    "                \n",
    "                # Apply angle rule to count fingers\n",
    "                a = ((end[0] - start[0])**2 + (end[1] - start[1])**2)**0.5\n",
    "                b = ((far[0] - start[0])**2 + (far[1] - start[1])**2)**0.5\n",
    "                c = ((end[0] - far[0])**2 + (end[1] - far[1])**2)**0.5\n",
    "                angle = (a**2 + b**2 - c**2) / (2*a*b)\n",
    "                \n",
    "                # If angle between fingers is less than 90 degrees, it's considered as a finger\n",
    "                if angle <= 0.5:\n",
    "                    fingers += 1\n",
    "            \n",
    "            if fingers == 4:  # We count the valleys (4) for 5 fingers\n",
    "                return \"Five fingers\"\n",
    "    return \"Not five fingers\"\n",
    "\n",
    "def show_frames():\n",
    "    # Capture the current frame\n",
    "    ret, frame = cap.read()\n",
    "      \n",
    "    # Detect the number of fingers\n",
    "    gesture = detect_five_fingers(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    # Repeat after an interval to capture continuously\n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "\n",
    "def parse_videos():\n",
    "    # Capture the current frame\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    while ret:\n",
    "        # run with the functions we tested before, and write the process frame into the video file\n",
    "        # image_process = preprocess_image(image)\n",
    "        # image_detect = draw_detected_cat(image_process)\n",
    "        # vidwrite.write(image_detect) # write frame into video\n",
    "\n",
    "        # Detect the number of fingers\n",
    "        gesture = detect_five_fingers(frame)\n",
    "    \n",
    "        # Update the gesture name variable\n",
    "        gesture_name_var.set(gesture)\n",
    "    \n",
    "        # Convert the image from BGR to RGB\n",
    "        cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(cv2image)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        video_label.imgtk = imgtk\n",
    "        video_label.configure(image=imgtk)\n",
    "    \n",
    "        # Repeat after an interval to capture continuously\n",
    "        time.sleep(0.01)\n",
    "        root.update()\n",
    "        \n",
    "        ret, frame = cap.read() # read frame from video\n",
    "    \n",
    "# Start the GUI\n",
    "if WEBCAM:\n",
    "    show_frames()\n",
    "else:\n",
    "    parse_videos()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T22:40:02.087183200Z",
     "start_time": "2024-02-11T22:40:00.607086700Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Recognition\")\n",
    "\n",
    "# Create a label to display the video frames\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a text box to display the gesture name\n",
    "gesture_name_var = tk.StringVar()\n",
    "gesture_name_entry = tk.Entry(root, textvariable=gesture_name_var, font=('Arial', 14), state='readonly')\n",
    "gesture_name_entry.pack()\n",
    "\n",
    "if WEBCAM:\n",
    "    # Access the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "def filter_skin(image):\n",
    "    # Convert to YCrCb color space, which is better for skin color detection\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define lower and upper bounds for skin color\n",
    "    lower_bound = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    upper_bound = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "    \n",
    "    # Create a mask for skin color\n",
    "    mask = cv2.inRange(ycrcb, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to get the skin region\n",
    "    skin_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return skin_region\n",
    "\n",
    "\n",
    "def preprocess_for_contours(image):\n",
    "    # Filter skin color first\n",
    "    skin_region = filter_skin(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    \n",
    "    # Thresholding to get the hand segment\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "\n",
    "\n",
    "# Function to detect fist\n",
    "def detect_fist(image):\n",
    "    skin_region = filter_skin(image)\n",
    "    # Convert to grayscale\n",
    "\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    \n",
    "    # Thresholding to get the hand segment\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Assume the largest contour is the hand\n",
    "        hand_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(hand_contour)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Approximate the contour to a polygon\n",
    "        approx = cv2.approxPolyDP(hand_contour, 0.02*cv2.arcLength(hand_contour, True), True)\n",
    "        \n",
    "        # If the number of vertices is small, we might have a fist\n",
    "        if len(approx) < 5:\n",
    "            return \"Fist\",image\n",
    "    return \"Not Fist\", image\n",
    "\n",
    "\n",
    "def detect_five_fingers(image):\n",
    "\n",
    "    skin_region = filter_skin(image)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(skin_region, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    \n",
    "    # Thresholding to get the hand segment\n",
    "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Assume the largest contour is the hand\n",
    "        hand_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(hand_contour)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        \n",
    "        # Approximate the contour to a polygon\n",
    "        approx = cv2.approxPolyDP(hand_contour, 0.02*cv2.arcLength(hand_contour, True), True)\n",
    "        \n",
    "        # Convex Hull\n",
    "        hull = cv2.convexHull(hand_contour, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(hand_contour, hull)\n",
    "        \n",
    "        # Finger counting\n",
    "        if defects is not None:\n",
    "            fingers = 0\n",
    "            for i in range(defects.shape[0]):\n",
    "                s, e, f, d = defects[i, 0]\n",
    "                start = tuple(hand_contour[s][0])\n",
    "                end = tuple(hand_contour[e][0])\n",
    "                far = tuple(hand_contour[f][0])\n",
    "                \n",
    "                # Apply angle rule to count fingers\n",
    "                a = ((end[0] - start[0])**2 + (end[1] - start[1])**2)**0.5\n",
    "                b = ((far[0] - start[0])**2 + (far[1] - start[1])**2)**0.5\n",
    "                c = ((end[0] - far[0])**2 + (end[1] - far[1])**2)**0.5\n",
    "                angle = (a**2 + b**2 - c**2) / (2*a*b)\n",
    "                \n",
    "                # If angle between fingers is less than 90 degrees, it's considered as a finger\n",
    "                if angle <= 0.5:\n",
    "                    fingers += 1\n",
    "            \n",
    "            if fingers == 4:  # We count the valleys (4) for 5 fingers\n",
    "                return \"Five fingers\", image\n",
    "    return \"Not five fingers\", image\n",
    "# Modify the existing function to handle both fist and five fingers\n",
    "def detect_gestures(image):\n",
    "    fist, image_with_box = detect_fist(image)\n",
    "    if fist == \"Fist\":\n",
    "        return \"Fist\", image_with_box\n",
    "    \n",
    "    five_fingers, image_with_box = detect_five_fingers(image)\n",
    "    if five_fingers == \"Five fingers\":\n",
    "        return \"Five fingers\", image_with_box\n",
    "    \n",
    "    return \"Unknown gesture\", image\n",
    "\n",
    "# Update the show_frames function to use the new detect_gestures function\n",
    "def show_frames():\n",
    "    # Capture the current frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Detect the gesture\n",
    "    gesture, frame_with_box = detect_gestures(frame)\n",
    "    \n",
    "    # Update the gesture name variable\n",
    "    gesture_name_var.set(gesture)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    cv2image = cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "    \n",
    "    # Repeat after an interval to capture continuously\n",
    "    video_label.after(20, show_frames)\n",
    "\n",
    "# Start the GUI\n",
    "if WEBCAM:\n",
    "    show_frames()\n",
    "else:\n",
    "    parse_videos()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the GUI is closed\n",
    "cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
