{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.601727500Z",
     "start_time": "2024-02-15T02:59:15.585329Z"
    }
   },
   "id": "6ac596a2f72fda19"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def resize_and_crop_image(image):\n",
    "    ratio = 1\n",
    "    max_edge = max(image.shape[0], image.shape[1])\n",
    "    while max_edge > 1000:\n",
    "        ratio *= 2\n",
    "        max_edge //= 2\n",
    "\n",
    "    rows = image.shape[0] // ratio\n",
    "    cols = image.shape[1] // ratio\n",
    "\n",
    "    # print(f\"resize ratio = {ratio}.\")\n",
    "    image_resized = cv2.resize(image, (cols, rows))\n",
    "    # print(image_resized.shape)\n",
    "    if CROP:\n",
    "        size = min(cols, rows)\n",
    "        return image_resized[:size, :size]\n",
    "    else:\n",
    "        return image_resized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.601727500Z",
     "start_time": "2024-02-15T02:59:15.588348500Z"
    }
   },
   "id": "a05f8989520cb862"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def RGBRange(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_skin = np.array([0, 48, 80], dtype=\"uint8\")\n",
    "    upper_skin = np.array([20, 255, 255], dtype=\"uint8\")\n",
    "    skinMask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "    skin = cv2.bitwise_and(image, image, mask=skinMask)\n",
    "    return skin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.602731500Z",
     "start_time": "2024-02-15T02:59:15.591522100Z"
    }
   },
   "id": "a6b8f441e41eba21"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "def morph_image(image,morph, kernel_size):\n",
    "    def erosion(image_cv, kernel_size = 4):\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))\n",
    "        image_cv_eroded = cv2.erode(image_cv, kernel)\n",
    "        return image_cv_eroded\n",
    "    def dilate(image_cv, kernel_size = 4):\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))\n",
    "        image_cv_dilated = cv2.dilate(image_cv, kernel)\n",
    "        return image_cv_dilated\n",
    "    if morph == 'dilate':\n",
    "        image_morphed = dilate(image,kernel_size = kernel_size)\n",
    "    elif morph == 'erode':\n",
    "        image_morphed = erosion(image,kernel_size = kernel_size)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return image_morphed\n",
    "\n",
    "def BinaryThreshold(image):\n",
    "    threshold = 145\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_thresh = cv2.threshold(img_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    img_thresh = morph_image(img_thresh, morph='erode', kernel_size=6)\n",
    "    img_thresh = morph_image(img_thresh, morph='dilate', kernel_size=6)\n",
    "    return img_thresh\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.602731500Z",
     "start_time": "2024-02-15T02:59:15.596150Z"
    }
   },
   "id": "6ae91d732e7e329a"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "def CannyEdgeDetection(img, lb=50, ub=100):\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # blurred = gray\n",
    "\n",
    "    # Detect edges using the Canny algorithm\n",
    "    edges = cv2.Canny(blurred, lb, ub)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "\n",
    "def CannyEdgeMaskGeneration(img):\n",
    "\n",
    "    edges = CannyEdgeDetection(img, 50, 100)\n",
    "\n",
    "    # Generate a mask: edges in white, background in black\n",
    "    mask = np.zeros_like(edges)\n",
    "    mask[edges > 0] = 255  # Set the white color to the edges detected by Canny\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def CannyObjectMaskGeneration(img):\n",
    "    # Detect edges using the Canny Edge Detection algorithm with low and high threshold values.\n",
    "    edges = CannyEdgeDetection(img, 10, 20)\n",
    "\n",
    "    # Use morphological operations to close the edges\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    closing = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours in the closed edge image\n",
    "    contours, _ = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Return an empty mask if no contours are found\n",
    "    if not contours:\n",
    "        return np.zeros(edges.shape, dtype=np.uint8)\n",
    "\n",
    "    # Assume the largest contour corresponds to the hand\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a mask of the same size as the edge image\n",
    "    mask = np.zeros(edges.shape, dtype=np.uint8)\n",
    "\n",
    "    # Fill in the contour of the detected hand\n",
    "    cv2.drawContours(mask, [largest_contour], -1, color=255, thickness=cv2.FILLED)\n",
    "\n",
    "    return mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.602731500Z",
     "start_time": "2024-02-15T02:59:15.600829800Z"
    }
   },
   "id": "988634e4a7198bad"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "def get_contours(img_thresh):\n",
    "    contours, hierarchy = cv2.findContours(img_thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def draw_contours(cv_image, contours, fill='line'):\n",
    "    if fill=='solid':\n",
    "        cv_image_out = cv2.drawContours(cv_image, contours, -1, (0,255,0), cv2.FILLED)\n",
    "    else:\n",
    "        cv_image_out = cv2.drawContours(cv_image, contours, -1, (0,255,0), 1)\n",
    "    return cv_image_out\n",
    "\n",
    "def draw_detected(img):\n",
    "    img_thresh = BinaryThreshold(img)\n",
    "    contours = get_contours(img_thresh)\n",
    "    crop_img = draw_contours(img, contours, fill='solid')\n",
    "    return crop_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.610188500Z",
     "start_time": "2024-02-15T02:59:15.604731200Z"
    }
   },
   "id": "f37484f914bae6a"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def get_hand_bbox_on_img(img, mask):\n",
    "    \"\"\"\n",
    "    Takes an image and a corresponding hand mask, finds the largest contour in the mask,\n",
    "    assumed to be the hand, and draws a bounding box around it on the original image.\n",
    "    If no hand is detected, it returns the original image unmodified.\n",
    "    \n",
    "    :param img: Original image\n",
    "    :param mask: Binary mask of the hand\n",
    "    :return: The original image with the bounding box drawn around the hand (if detected),\n",
    "             and the bounding box coordinates (x, y, w, h) or None if no hand is detected.\n",
    "    \"\"\"\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Assume the largest contour is the hand\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        # Calculate bounding box for the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "        # Draw bounding box on the original image\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        return img, (x, y, w, h)\n",
    "    else:\n",
    "        # Return the original image if no contours are found\n",
    "        return img, None\n",
    "\n",
    "def draw_hand_bbox_from_mask(img, mask):\n",
    "    img_with_bbox, bbox = get_hand_bbox_on_img(img, mask)\n",
    "    \n",
    "    if SHOW:\n",
    "        cv2.imshow('Hand with Bounding Box', img_with_bbox)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.610188500Z",
     "start_time": "2024-02-15T02:59:15.608003700Z"
    }
   },
   "id": "1be770de97bc3584"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "def get_bbox_from_hv_projection(img, mask):\n",
    "    \"\"\"\n",
    "    Given an image and its binary mask, this function calculates horizontal and vertical projections\n",
    "    of the mask to find the bounding box around the largest area of interest. It then draws\n",
    "    this bounding box on the original image. If no significant area is detected, it returns\n",
    "    the original image unmodified.\n",
    "\n",
    "    :param img: The original image.\n",
    "    :param mask: The binary mask highlighting areas of interest.\n",
    "    :return: The original image with the bounding box drawn around the detected area (if any),\n",
    "             and the bounding box coordinates (x, y, w, h), or None if no area is detected.\n",
    "    \"\"\"\n",
    "    # Calculate horizontal and vertical projections of the mask\n",
    "    horizontal_projection = np.sum(mask, axis=0)\n",
    "    vertical_projection = np.sum(mask, axis=1)\n",
    "\n",
    "    # Find non-zero values in projections to determine bounds\n",
    "    h_non_zero_indices = np.nonzero(horizontal_projection)[0]\n",
    "    v_non_zero_indices = np.nonzero(vertical_projection)[0]\n",
    "\n",
    "    if h_non_zero_indices.size > 0 and v_non_zero_indices.size > 0:\n",
    "        # Determine bounding box coordinates\n",
    "        x1, x2 = h_non_zero_indices[[0, -1]]\n",
    "        y1, y2 = v_non_zero_indices[[0, -1]]\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "\n",
    "        # Draw bounding box on the original image\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        return img, (x1, y1, w, h)\n",
    "    else:\n",
    "        # Return the original image if no significant area is detected\n",
    "        return img, None\n",
    "\n",
    "def draw_bbox_from_hv_projection(img, mask):\n",
    "    img_with_bbox, bbox = get_bbox_from_hv_projection(img, mask)\n",
    "\n",
    "    if SHOW:\n",
    "        cv2.imshow('Image with Bounding Box', img_with_bbox)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.646107400Z",
     "start_time": "2024-02-15T02:59:15.612188200Z"
    }
   },
   "id": "a63ed011557f3931"
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def processSingleImage(process_func):\n",
    "    # Create video capture object\n",
    "    vidCap = cv2.VideoCapture(FVideo)\n",
    "    \n",
    "    # Process video frames\n",
    "    success, image = vidCap.read()\n",
    "    assert success\n",
    "    \n",
    "    cv2.imwrite(FFirst, image)\n",
    "    \n",
    "    mask = process_func(image)\n",
    "    # Show the result\n",
    "    if SHOW:\n",
    "        cv2.imshow(\"object detection\", mask)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    draw_hand_bbox_from_mask(image, mask)\n",
    "    \n",
    "    # detected_img = draw_detected(image)\n",
    "    # cv2.imshow(\"detected image\", detected_img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    if not EXP:\n",
    "        # Get video properties for the output video\n",
    "        fps = vidCap.get(cv2.CAP_PROP_FPS)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "        # frame_width = int(vidCap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        # frame_height = int(vidCap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        w, h = mask.shape[:2]\n",
    "        out = cv2.VideoWriter(FOutput, fourcc, fps, (h, w))\n",
    "        outBbox = cv2.VideoWriter(FOutputBBox, fourcc, fps, (h, w))\n",
    "    \n",
    "        while success:\n",
    "            # Apply skin detection\n",
    "            mask = process_func(image)\n",
    "    \n",
    "            if len(mask.shape) == 2:\n",
    "                BGRImg = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "            else:\n",
    "                BGRImg = mask\n",
    "    \n",
    "            # Write the processed frame\n",
    "            out.write(BGRImg)\n",
    "    \n",
    "            img_with_bbox, bbox = get_hand_bbox_on_img(image, mask)\n",
    "            outBbox.write(img_with_bbox)\n",
    "    \n",
    "            success, image = vidCap.read()\n",
    "    \n",
    "        out.release()\n",
    "        outBbox.release()\n",
    "    \n",
    "    # Release resources\n",
    "    vidCap.release()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.648234400Z",
     "start_time": "2024-02-15T02:59:15.617164Z"
    }
   },
   "id": "a16f7b7822549369"
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "def find_motion_blobs(frame1, frame2, threshold=25):\n",
    "    # Calculate the difference between two frames and convert the result to grayscale\n",
    "    frame_diff = cv2.absdiff(frame1, frame2)\n",
    "    if len(frame_diff.shape) == 3:\n",
    "        gray_diff = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_diff = frame_diff\n",
    "\n",
    "    # Apply a threshold to identify significant changes\n",
    "    _, thresh = cv2.threshold(gray_diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Use dilation to fill in small holes in the image for easier processing\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours\n",
    "\n",
    "\n",
    "def Blob():\n",
    "    cap = cv2.VideoCapture(FVideo)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        exit()\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read the first frame.\")\n",
    "        cap.release()\n",
    "        exit()\n",
    "    \n",
    "    # Convert the first frame to grayscale\n",
    "    prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    out = None\n",
    "    if not EXP:\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        w, h = prev_frame.shape[:2]\n",
    "        out = cv2.VideoWriter(FOutput, fourcc, fps, (h, w))\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame = resize_and_crop_image(frame)\n",
    "    \n",
    "        # Convert the current frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Find motion areas\n",
    "        contours = find_motion_blobs(prev_frame, gray_frame)\n",
    "    \n",
    "        # Draw bounding boxes on the original frame\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 500:\n",
    "                continue  # Ignore small areas\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "        if not EXP:\n",
    "            out.write(frame)\n",
    "    \n",
    "        if SHOW:\n",
    "            cv2.imshow('Motion Detection', frame)\n",
    "        prev_frame = gray_frame\n",
    "\n",
    "        if EXP:\n",
    "            cv2.waitKey(0)\n",
    "            break\n",
    "    \n",
    "        else:\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "    if not EXP:\n",
    "        out.release()\n",
    "    \n",
    "    cap.release()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.648234400Z",
     "start_time": "2024-02-15T02:59:15.621433800Z"
    }
   },
   "id": "6dc8c7e3c89b10b8"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "# Define a dictionary that maps mode strings to their corresponding processing methods\n",
    "process_single_frame_methods = {\n",
    "    \"rgb\": RGBRange,\n",
    "    \"grey\": BinaryThreshold,\n",
    "    \"canny\": CannyObjectMaskGeneration, \n",
    "    \"cannyEdge\": CannyEdgeMaskGeneration,\n",
    "}\n",
    "\n",
    "process_video_methods = {\n",
    "    \"blob\": Blob\n",
    "}\n",
    "\n",
    "\n",
    "def work(mode):\n",
    "    \n",
    "    # Use the mode to get the corresponding process method from the dictionary\n",
    "    process_method = process_single_frame_methods.get(mode, None)\n",
    "    \n",
    "    if process_method is not None:\n",
    "        # single\n",
    "        def process_func(image):\n",
    "            return process_method(resize_and_crop_image(image))\n",
    "        \n",
    "        processSingleImage(process_func)\n",
    "        \n",
    "    else:\n",
    "        process_method = process_video_methods.get(mode, None)\n",
    "    \n",
    "        # If mode does not match any key in the dictionary, process_method will be None   \n",
    "        assert process_method is not None\n",
    "        \n",
    "        process_method()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.648234400Z",
     "start_time": "2024-02-15T02:59:15.624946400Z"
    }
   },
   "id": "6dfc3eb0f6d91a0a"
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "EXP = False\n",
    "CROP = False\n",
    "HPV = True\n",
    "mode = \"blob\"\n",
    "SHOW = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:15.648234400Z",
     "start_time": "2024-02-15T02:59:15.628484200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "VIDEO_NAME = \"fingers\"\n",
    "FVideo = f'videos/{VIDEO_NAME}.mp4'\n",
    "WORKDIR = f\"videos/{VIDEO_NAME}/\"\n",
    "os.makedirs(WORKDIR, exist_ok=True)\n",
    "\n",
    "for mode in [\"grey\", \"canny\", \"blob\"]:\n",
    "\n",
    "    FFirst = WORKDIR + \"first.png\"  # Filename for the first frame image\n",
    "    FOutput = WORKDIR + f\"{mode}.mp4\"  # Filename for the output video\n",
    "        \n",
    "    if HPV:\n",
    "        FOutputBBox = WORKDIR + f\"{mode}_bbox_HPV.mp4\"  # Filename for the output video with bbox\n",
    "    else:\n",
    "        FOutputBBox = WORKDIR + f\"{mode}_bbox.mp4\"  # Filename for the output video with bbox\n",
    "    \n",
    "    work(mode)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:19.278574300Z",
     "start_time": "2024-02-15T02:59:15.632600200Z"
    }
   },
   "id": "80014025e72dab2"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:19.284638400Z",
     "start_time": "2024-02-15T02:59:19.279950500Z"
    }
   },
   "id": "57f7a9b762201c55"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T02:59:19.286141700Z",
     "start_time": "2024-02-15T02:59:19.282131200Z"
    }
   },
   "id": "f956e68b713ad4b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
