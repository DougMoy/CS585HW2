{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "U_HgosxkrKu4",
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:36.045106200Z",
     "start_time": "2024-02-13T22:40:36.033726400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nCS585_Lab3\\nCS585 Image and Video Computing\\nLab 3\\n--------------\\nThis program introduces the following concepts:\\n\\ta) Reading a stream of images from a webcamera, and displaying the video\\n\\tb) Skin color detection\\n\\tc) Background differencing\\n\\td) Visualizing motion history\\n--------------\\n'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "'''\n",
    "CS585_Lab3\n",
    "CS585 Image and Video Computing\n",
    "Lab 3\n",
    "--------------\n",
    "This program introduces the following concepts:\n",
    "\ta) Reading a stream of images from a webcamera, and displaying the video\n",
    "\tb) Skin color detection\n",
    "\tc) Background differencing\n",
    "\td) Visualizing motion history\n",
    "--------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# PART 1: object detection by skin color\n",
    "\n",
    "# step 1,\n",
    "# play a video\n",
    "# Because I am using Google Colab, so I am not able to play video\n",
    "# with the OpenCV window. Therefore I have to download the video and play it.\n",
    "\n",
    "# In your case, if you are running OpenCV with a local desktop and\n",
    "# set up the OpenCV correctly, you should consider the following ways\n",
    "# to display video or anything captured by your camera.\n",
    "\n",
    "# https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html"
   ],
   "metadata": {
    "id": "fkEm2zEQsseA",
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:36.045106200Z",
     "start_time": "2024-02-13T22:40:36.036164800Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# VIDEO_NAME = \"thumbUp\"\n",
    "VIDEO_NAME = \"fingers\"\n",
    "# VIDEO_NAME = \"cat\"\n",
    "FVideo = f'videos/{VIDEO_NAME}.mp4'\n",
    "WORKDIR = f\"videos/{VIDEO_NAME}/\"\n",
    "os.makedirs(WORKDIR, exist_ok=True)\n",
    "FFirst = WORKDIR + \"first.png\"  # file of first image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:36.045106200Z",
     "start_time": "2024-02-13T22:40:36.038887Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "SHOW = False\n",
    "CROP = False\n",
    "\n",
    "THRESHOLD = 145"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:36.046108200Z",
     "start_time": "2024-02-13T22:40:36.042147500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HayzlbMwrKu7",
    "outputId": "4c511b8c-b023-4670-85da-9e4ffb1063d8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:36.078531200Z",
     "start_time": "2024-02-13T22:40:36.046108200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# step 2:\n",
    "# To detect the cat in the video, it's not convenient to work with multiple frames\n",
    "# in the beginning.\n",
    "# Thus we should extract one or the first few frames in the video, and work on them first.\n",
    "\n",
    "vidcap = cv2.VideoCapture(FVideo)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "\n",
    "cv2.imwrite(FFirst, image)     # save the frame as JPEG file"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# I reuse some of the functions implemented in the last lab to save some time\n",
    "# A more \"organized\" way to do it is to import it from our lab1.py\n",
    "\n",
    "def morph_image(image,morph, kernel_size):\n",
    "  def erosion(image_cv, kernel_size = 4):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))\n",
    "    image_cv_eroded = cv2.erode(image_cv, kernel)\n",
    "    return image_cv_eroded\n",
    "  def dilate(image_cv, kernel_size = 4):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))\n",
    "    image_cv_dilated = cv2.dilate(image_cv, kernel)\n",
    "    return image_cv_dilated\n",
    "  if morph == 'dilate':\n",
    "    image_morphed = dilate(image,kernel_size = kernel_size)\n",
    "  elif morph == 'erode':\n",
    "    image_morphed = erosion(image,kernel_size = kernel_size)\n",
    "  else:\n",
    "    raise NotImplementedError\n",
    "  return image_morphed\n",
    "\n",
    "def get_contours(cv_image_thres):\n",
    "  contours, hierarchy = cv2.findContours(cv_image_thres, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  return contours\n",
    "def draw_contours(cv_image, contours,fill='line'):\n",
    "  if fill=='solid':\n",
    "    cv_image_out = cv2.drawContours(cv_image, contours, -1,(0,255,0),cv2.FILLED)\n",
    "  else:\n",
    "    cv_image_out = cv2.drawContours(cv_image, contours, -1,(0,255,0),1)\n",
    "  return cv_image_out\n",
    "\n",
    "def get_largest_contour(contours):\n",
    "  max_area = 0\n",
    "  max_i = -1\n",
    "  for i,contour in enumerate(contours):\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > max_area:\n",
    "      max_i = i\n",
    "      max_area = area\n",
    "  return [contours[max_i]]"
   ],
   "metadata": {
    "id": "nuERbxsM0aLG",
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:36.078531200Z",
     "start_time": "2024-02-13T22:40:36.063324800Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "S4AsPEWUrKu8",
    "outputId": "ada667bf-b255-4079-d348-754c1f8e3e9b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:36.079536100Z",
     "start_time": "2024-02-13T22:40:36.066774700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image.shape (568, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# One of the things to pay attention to in computer vision is\n",
    "# always the size of images you are dealing with, the bigger it is,\n",
    "# the more time it takes any algorithm to process it,\n",
    "# so it is always preferable to resize the image to a smaller one first.\n",
    "# the cost is the lost of \"details\" in a high resolution image,\n",
    "# but during most of the cases, this is trivial.\n",
    "\n",
    "def load_image(image_path):\n",
    "  image = cv2.imread(image_path)\n",
    "  return image\n",
    "\n",
    "\n",
    "def resize_and_crop_image(image):\n",
    "  rows = image.shape[0]\n",
    "  cols = image.shape[1]\n",
    "\n",
    "  # # resize the image size to be 1/10 of the original one\n",
    "  # cat_image_resized = cv2.resize(image,(cols//10,rows//10))\n",
    "  # # we can further crop the image to focus on the cat\n",
    "  # crop_img = cat_image_resized[:cols//10, :cols//10]\n",
    "\n",
    "  # resize\n",
    "  ratio = max(max(rows, cols) // 640, 1)\n",
    "  # print(f\"resize ratio = {ratio}.\")\n",
    "  image_resized = cv2.resize(image,(cols//ratio,rows//ratio))\n",
    "  # print(image_resized.shape)\n",
    "  if CROP:\n",
    "    size = min(cols, rows) // ratio\n",
    "    crop_img = image_resized[:size, :size]\n",
    "  else:\n",
    "    crop_img = image_resized\n",
    "  # print(crop_img.shape)\n",
    "\n",
    "  return crop_img\n",
    "\n",
    "\n",
    "# let's test with our first frame of the video\n",
    "cat_image = load_image(FFirst) # the image size (4096 * 2160, 3)is too large, which is not good for efficiency\n",
    "print(\"first image.shape\", cat_image.shape)\n",
    "\n",
    "cat_image_cropped = resize_and_crop_image(cat_image)\n",
    "\n",
    "\n",
    "if SHOW:\n",
    "  # check if the image is small enough\n",
    "  # cv2_imshow(cat_image_cropped)\n",
    "  cv2.imshow(\"cropped image\", cat_image_cropped)\n",
    "  cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# step 3,\n",
    "# skin detection, since the cat is white, the most straight-forward way is to turn it into binary image with\n",
    "# a suitable threshold, and after that, find contours\n",
    "# (and maybe just keep the largest one for better precision).\n",
    "# to save our time, simply reuse the functions we learned from the last lab section\n",
    "\n",
    "cat_image = load_image(FFirst) # the image size (4096 * 2160, 3)is too large, which is not good for efficiency\n",
    "cat_image_cropped = resize_and_crop_image(cat_image)\n",
    "\n",
    "crop_img_gray = cv2.cvtColor(cat_image_cropped,cv2.COLOR_BGR2GRAY)\n",
    "_,crop_img_thres = cv2.threshold(crop_img_gray, THRESHOLD, 255, cv2.THRESH_BINARY) \n",
    "\n",
    "if SHOW:\n",
    "  # cv2_imshow(crop_img_thres)\n",
    "  cv2.imshow(\"cropped image threshold\", cat_image_cropped)\n",
    "  cv2.waitKey(0)\n",
    "\n",
    "crop_img_thres = morph_image(crop_img_thres,morph='erode',kernel_size=6)\n",
    "crop_img_thres = morph_image(crop_img_thres,morph='dilate',kernel_size=6)\n",
    "\n",
    "# Here if you want the result to be more precise or you need\n",
    "# the boundary info of the \"cat\" object,\n",
    "# you can also find the largest contour like we did\n",
    "# in our last lab:\n",
    "\n",
    "# contours = get_contours(crop_img_thres)\n",
    "# largest_contour = get_largest_contour(contours)\n",
    "# draw_contours(...), so on and so forth\n",
    "\n",
    "if SHOW:\n",
    "  # cv2_imshow(crop_img_gray)\n",
    "  cv2.imshow(\"cropped image gray\", cat_image_cropped,)\n",
    "  cv2.waitKey(0)\n",
    "  \n",
    "  # cv2_imshow(crop_img_thres)\n",
    "  cv2.imshow(\"cropped image threshold\", cat_image_cropped)\n",
    "  cv2.waitKey(0)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "id": "3PNcLrXzyB46",
    "outputId": "5527702d-ebaf-42cd-cfc5-a4bdf8dd7720",
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:36.079536100Z",
     "start_time": "2024-02-13T22:40:36.075503700Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# step 4,\n",
    "# Detect the cat in every frame and output the processed video\n",
    "# for better readability, let's wrap everything we did before into some functions\n",
    "# first:\n",
    "\n",
    "def preprocess_image(captured_image):\n",
    "  return resize_and_crop_image(captured_image)\n",
    "  \n",
    "# def preprocess_image(captured_image):\n",
    "#   rows = captured_image.shape[0]\n",
    "#   cols = captured_image.shape[1]\n",
    "#   cat_image_resized = cv2.resize(captured_image,(cols//10,rows//10))\n",
    "#   # we can further crop the image to focus on the cat\n",
    "#   crop_img = cat_image_resized[:cols//10, :cols//10]\n",
    "#   return crop_img\n",
    "\n",
    "\n",
    "def draw_detected_cat(crop_img):\n",
    "  crop_img_gray = cv2.cvtColor(crop_img,cv2.COLOR_BGR2GRAY)\n",
    "  _,crop_img_thres = cv2.threshold(crop_img_gray, THRESHOLD, 255, cv2.THRESH_BINARY) # 180 and 255 are hyper-parameters\n",
    "  crop_img_thres = morph_image(crop_img_thres,morph='erode',kernel_size=6)\n",
    "  crop_img_thres = morph_image(crop_img_thres,morph='dilate',kernel_size=6)\n",
    "  contours = get_contours(crop_img_thres)\n",
    "  crop_img = draw_contours(crop_img,contours,fill='solid')\n",
    "  return crop_img\n",
    "\n",
    "# output the video with our processed frame\n",
    "vidcap = cv2.VideoCapture(FVideo)\n",
    "success, image = vidcap.read()\n",
    "image_process = preprocess_image(image)\n",
    "assert success\n",
    "w, h = image_process.shape[:2]\n",
    "vidwrite = cv2.VideoWriter(WORKDIR + \"detected.mp4\", cv2.VideoWriter_fourcc(*'MP4V'), 30, (h, w))\n",
    "\n",
    "while success:\n",
    "  # run with the functions we tested before, and write the process frame into the video file\n",
    "  image_process = preprocess_image(image)\n",
    "  image_detect = draw_detected_cat(image_process)\n",
    "\n",
    "  print(image_process.shape)\n",
    "  print(image_detect.shape)\n",
    "  print(image.shape)\n",
    "  \n",
    "  cv2.imshow(\"detected\", image_detect)\n",
    "  cv2.waitKey(0)\n",
    "  print(image_detect.shape)\n",
    "  break\n",
    "  \n",
    "  vidwrite.write(image_detect) # write frame into video\n",
    "  success,image = vidcap.read() # read frame from video\n",
    "vidwrite.release()"
   ],
   "metadata": {
    "id": "FnOG-LXk0fjy",
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:37.133402700Z",
     "start_time": "2024-02-13T22:40:36.081534700Z"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568, 320, 3)\n",
      "(568, 320, 3)\n",
      "(568, 320, 3)\n",
      "(568, 320, 3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bur6VZ5lrKu-",
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:37.467273200Z",
     "start_time": "2024-02-13T22:40:37.123402500Z"
    }
   },
   "outputs": [],
   "source": [
    "# PART 2\n",
    "# Motion history\n",
    "# Here we compare the intensity difference between neighboring frames,\n",
    "# And then acculumate the differences and draw then in a \"white\" canvas to visualize\n",
    "# the track of motion, in this case, mostly the motion of cat.\n",
    "\n",
    "# It is the same idea, but this time you need additional arrays/images to achieve the goal\n",
    "import numpy as np\n",
    "\n",
    "# We did thresholding here because we want to get rid of the difference caused by the moving camera\n",
    "def thresholding(image):\n",
    "  crop_img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "  _,crop_img_thres = cv2.threshold(crop_img_gray, THRESHOLD, 255, cv2.THRESH_BINARY) # 180 and 255 are hyper-parameters\n",
    "  crop_img_thres = morph_image(crop_img_thres,morph='erode',kernel_size=6)\n",
    "  crop_img_thres = morph_image(crop_img_thres,morph='dilate',kernel_size=20)\n",
    "  return crop_img_thres\n",
    "\n",
    "# use cv2.absdiff or some numpy functions, it is up to you\n",
    "# but cv2.absdiff seems to be more convenient.\n",
    "def frame_differencing(image_last,image_cur):\n",
    "  image_diff = cv2.absdiff(image_last, image_cur)\n",
    "  image_diff_mask = (image_diff > 0) # probably don't need this but just in case\n",
    "  return image_diff_mask\n",
    "\n",
    "# build a \"white\" canvas (its all black)\n",
    "def init_canvas(size,mode='color'):\n",
    "  cols,rows = size\n",
    "  if mode == 'color':\n",
    "    canvas = np.zeros((rows,cols,3)).astype(np.uint8)\n",
    "  elif mode == 'grayscale':\n",
    "    canvas = np.zeros((rows,cols))\n",
    "  elif mode == 'binary':\n",
    "    canvas = np.zeros((rows,cols)).astype(np.uint8)\n",
    "  else:\n",
    "    raise NotImplementedError\n",
    "  return canvas\n",
    "\n",
    "# same as PART 1\n",
    "vidcap = cv2.VideoCapture(FVideo)\n",
    "success, image = vidcap.read()\n",
    "assert success\n",
    "w, h = image_process.shape[:2]\n",
    "vidwrite = cv2.VideoWriter(WORKDIR + \"motion.mp4\", cv2.VideoWriter_fourcc(*'MP4V'), 30, (h, w))\n",
    "\n",
    "# keep track of the intensity of pixels of the last frame\n",
    "image_last_process = preprocess_image(image)\n",
    "image_last_thres = thresholding(image_process)\n",
    "\n",
    "# init the canvas\n",
    "canvas = init_canvas((image_last_thres.shape[1],image_last_thres.shape[0]),mode='color')\n",
    "\n",
    "# same thing, load the frames of the video one by one\n",
    "while success:\n",
    "\n",
    "  # get the processed current frame\n",
    "  image_cur_process = preprocess_image(image)\n",
    "  image_cur_thres = thresholding(image_cur_process)\n",
    "\n",
    "  # compare difference\n",
    "  image_diff = frame_differencing(image_last_thres,image_cur_thres)\n",
    "  # change the format of the differencing result to apply to rgb channels\n",
    "  image_diff_mask = np.repeat(image_diff[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "  # accumulate the difference in the canvas, but mind the data type\n",
    "  canvas = np.logical_or(canvas.astype(bool),image_diff_mask).astype(np.uint8)*255\n",
    "  image_last_thres = image_cur_thres\n",
    "\n",
    "  vidwrite.write(canvas) # write frame into video\n",
    "  success,image = vidcap.read() # read frame from video\n",
    "\n",
    "vidwrite.release()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Further things to do:\n",
    "\n",
    "# OpenCV provides an access to capture camera input and return the image of each frame,\n",
    "# You should have a try if that interest you:\n",
    "# https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html\n",
    "\n",
    "\n",
    "# This might be very helpful if you are developing mobile apps with OpenCV, say in Android OS:\n",
    "# https://opencv.org/android/\n",
    "\n",
    "# We demonstrate the video processing with a very \"easy\" example which is a white cat, things\n",
    "# can be more interesting and complicated when trying to detect human, i.e., by their skin.\n",
    "# Here's an article provides a very straight-forward way to determine the skin pixel by\n",
    "# a range of colors\n",
    "# Vezhnevets, Vladimir, Vassili Sazonov, and Alla Andreeva. \"A survey on pixel-based skin color detection techniques.\" Proc. Graphicon. Vol. 3. 2003.\n",
    "# Kakumanu, Praveen, Sokratis Makrogiannis, and Nikolaos Bourbakis.\n",
    "# \"A survey of skin-color modeling and detection methods.\" Pattern recognition 40.3 (2007): 1106-1122.\n",
    "# https://www.graphicon.ru/html/2003/Proceedings/Technical/paper509.pdf\n",
    "# https://dl.acm.org/doi/abs/10.1016/j.patcog.2006.06.010\n",
    "\n",
    "# You can try to see if the algorithm detects your face."
   ],
   "metadata": {
    "id": "ShNhqa3quNok",
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:37.472929400Z",
     "start_time": "2024-02-13T22:40:37.467273200Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "3QMYA1bKCFxn",
    "ExecuteTime": {
     "end_time": "2024-02-13T22:40:37.472929400Z",
     "start_time": "2024-02-13T22:40:37.470421Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
